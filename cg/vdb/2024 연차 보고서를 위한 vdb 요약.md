
### 09-09

- CUDA-kmeans 구현
	-  개발 환경 설정
	-  CUDA-kmeans 알고리즘 구현
	- parameter(N, dim, k, iter)에 따른 클러스터링 결과
	- dim=2 에 한해서 matplot으로 시각화
	- GPU(2080 ti, 3090) 성능 측정 데이터

### 10-30

- Kmeans.cu 구현 및 설명

- 성능 측정 결과 업데이트
	- 4090 추가
	- CUDA-kmeans에 비해 시간이 오래 걸림
	- 4090의 경우 2080ti보다 5배 이상 빠른 성능을 보임
	- 대용량 데이터 처리를 위한 data load manager 개발 계획

### 11-06

- shared memory 최적화
	- ClusterAssingment, CentroidUpdate kernel 함수에서 shared memory 활용
	- 중복 메모리 접근 감소
	- atmoicAdd 연산을 통한 효율적인 데이터 누적
	- block 별 작업 완료 후 전역 메모리 업데이트 방식

- 성능 개선 결과
	- 2080ti 기준(ms) :
		- 1M 대용량 data points : 45057.3 ->39092.3 (약 13%)
		- 128K data points  : 2487.77 -> 1651.42 (약 34%)
	- 일부 케이스의 경우에는 성능 저하 발생(55.3646 -> 63.1644)

- OpenAI Embedding 관련 진행 사항
	- text-embedding-3-small 모델 사용
	- Amazon fine-food reviews dataset 활용 및 테스트
	- 1536차원 벡터 변환 작업 진행

### 11-18

- shared memory & chunk 최적화
	- gpu shared memory 용량 제한 문제 발견
	- dim = 1536일 때 100만개 데이터 셋 처리 시 메모리 부족 확인
	- chunk 기반 데이터 분할 처리 방식 도입
	- chunk_size에 따른 성능 측정 결과
		- 최적 성능: chunk_size 8 (139204ms)
		- 최저 성능: chunk_size 384 (431352ms)
		- 전반적으로 chunk 사이즈가 적당히 작을 때 좋은 성능

- OpenAI embedding dataset 관련
	-  openai_large_5m dataset 체크
	-  nytimes 대비 스펙
		- 6배 높은 dimension
		- 3배 큰 dataset 크기
		- 제안서 기준 개수는 100만개
	- parquet 형식이며 1536dim의 embedding dataset 확보
		- cpp에 맞게 포팅할 필요성 있음

### TBD

- 연차 보고서 및 차년도 계획서 작성
- parquet 데이터 로드 코드 작성
- chunk 코드 작성
- memory align 코드 작성























![[vdb1.png|600]]

![[vdb2.png|600]]

연구개발성과 3문장 요약 파트
당해년도 수행 일정 체크
당해년도 개발 내용

가) GPU 기반 데이터 파티셔닝 가속 기술 개발

나) GPU 기반 벡터 DB 데이터 로딩 가속 기술 개발

다) FPGA 기반 검색 가속 모듈 단위 설계



cuda 기반 k-means 알고리즘 곳어능 최적화 기법, 대규모 dataset에서 파티셔닝, 시각화